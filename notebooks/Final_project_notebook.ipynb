{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3977783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import data_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aaceec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opera (the U.S. title is terror at the opera) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heard about this film a long while ago and fin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is worth mentioning that is omitted in th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darling Lili is fantastic! Its by far one my f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I caught this little gem totally by accident b...  positive\n",
       "1  I can't believe that I let myself into this mo...  negative\n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative\n",
       "3  If there's one thing I've learnt from watching...  negative\n",
       "4  I remember when this was in theaters, reviews ...  negative\n",
       "5  Opera (the U.S. title is terror at the opera) ...  positive\n",
       "6  Heard about this film a long while ago and fin...  positive\n",
       "7  John Holmes is so famous, he's infamous (as th...  positive\n",
       "8  What is worth mentioning that is omitted in th...  positive\n",
       "9  Darling Lili is fantastic! Its by far one my f...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data = data_loader.load_data('../data/raw')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0284423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Opera (the U.S. title is terror at the opera) is somewhat of a letdown after some of Dario's other movies like Phenomena, Tenebre, and Suspiria. (i still can't find Inferno anywhere.) it's one of those movies that has a great first half but midway through it's like someone started slowly letting the air out of the screenplay and logic.<br /><br />the basic plot involves a beautiful opera singer who is being stalked by a deranged obsessed fan. this killer begins killing people close to her in a most unique fashion. he binds and gags her and tape tiny sharp pins under her eyelids so if she tries to close her eyes she'll gouge out her eyes. this forces her to watch while the killer murders her acquaintances in typically brutal and gory Argento fashion.<br /><br />unfortunately, about midway through the film becomes sluggish and illogical. (this is especially directed towards the killer's motivations. i still haven't completely figured out why he's such a nut.) the ending especially come out of left field in the worst possible sense.<br /><br />but, for about the first hour or so this is some of Dario's best filmmaking and the camera work is breathtaking. too bad it couldn't maintain it through to the end.<br /><br />rating:7\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['review'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a8a235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     40000 non-null  object\n",
      " 1   sentiment  40000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390cd5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22842342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    20000\n",
       "negative    20000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9c3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opera (the U.S. title is terror at the opera) ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heard about this film a long while ago and fin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is worth mentioning that is omitted in th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darling Lili is fantastic! Its by far one my f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  review_length\n",
       "0  I caught this little gem totally by accident b...  positive            892\n",
       "1  I can't believe that I let myself into this mo...  negative            937\n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative            468\n",
       "3  If there's one thing I've learnt from watching...  negative           1960\n",
       "4  I remember when this was in theaters, reviews ...  negative           1015\n",
       "5  Opera (the U.S. title is terror at the opera) ...  positive           1241\n",
       "6  Heard about this film a long while ago and fin...  positive           1127\n",
       "7  John Holmes is so famous, he's infamous (as th...  positive           3182\n",
       "8  What is worth mentioning that is omitted in th...  positive           2270\n",
       "9  Darling Lili is fantastic! Its by far one my f...  positive           1587"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['review_length'] = train_data['review'].str.len()\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac97c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>892</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>937</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>468</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1960</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1015</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opera (the U.S. title is terror at the opera) ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1241</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heard about this film a long while ago and fin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1127</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3182</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is worth mentioning that is omitted in th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2270</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darling Lili is fantastic! Its by far one my f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1587</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  review_length  \\\n",
       "0  I caught this little gem totally by accident b...  positive            892   \n",
       "1  I can't believe that I let myself into this mo...  negative            937   \n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative            468   \n",
       "3  If there's one thing I've learnt from watching...  negative           1960   \n",
       "4  I remember when this was in theaters, reviews ...  negative           1015   \n",
       "5  Opera (the U.S. title is terror at the opera) ...  positive           1241   \n",
       "6  Heard about this film a long while ago and fin...  positive           1127   \n",
       "7  John Holmes is so famous, he's infamous (as th...  positive           3182   \n",
       "8  What is worth mentioning that is omitted in th...  positive           2270   \n",
       "9  Darling Lili is fantastic! Its by far one my f...  positive           1587   \n",
       "\n",
       "   word_count  \n",
       "0         161  \n",
       "1         170  \n",
       "2          69  \n",
       "3         314  \n",
       "4         183  \n",
       "5         211  \n",
       "6         210  \n",
       "7         570  \n",
       "8         410  \n",
       "9         267  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(review):\n",
    "    review_list = review.split()\n",
    "    return len(review_list)\n",
    "\n",
    "train_data['word_count'] = train_data['review'].apply(word_count)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7875b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>892</td>\n",
       "      <td>161</td>\n",
       "      <td>4.546584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>937</td>\n",
       "      <td>170</td>\n",
       "      <td>4.517647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>468</td>\n",
       "      <td>69</td>\n",
       "      <td>5.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1960</td>\n",
       "      <td>314</td>\n",
       "      <td>5.245223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1015</td>\n",
       "      <td>183</td>\n",
       "      <td>4.551913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opera (the U.S. title is terror at the opera) ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1241</td>\n",
       "      <td>211</td>\n",
       "      <td>4.886256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heard about this film a long while ago and fin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1127</td>\n",
       "      <td>210</td>\n",
       "      <td>4.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3182</td>\n",
       "      <td>570</td>\n",
       "      <td>4.584211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is worth mentioning that is omitted in th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2270</td>\n",
       "      <td>410</td>\n",
       "      <td>4.539024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darling Lili is fantastic! Its by far one my f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1587</td>\n",
       "      <td>267</td>\n",
       "      <td>4.947566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  review_length  \\\n",
       "0  I caught this little gem totally by accident b...  positive            892   \n",
       "1  I can't believe that I let myself into this mo...  negative            937   \n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative            468   \n",
       "3  If there's one thing I've learnt from watching...  negative           1960   \n",
       "4  I remember when this was in theaters, reviews ...  negative           1015   \n",
       "5  Opera (the U.S. title is terror at the opera) ...  positive           1241   \n",
       "6  Heard about this film a long while ago and fin...  positive           1127   \n",
       "7  John Holmes is so famous, he's infamous (as th...  positive           3182   \n",
       "8  What is worth mentioning that is omitted in th...  positive           2270   \n",
       "9  Darling Lili is fantastic! Its by far one my f...  positive           1587   \n",
       "\n",
       "   word_count  mean_word_length  \n",
       "0         161          4.546584  \n",
       "1         170          4.517647  \n",
       "2          69          5.797101  \n",
       "3         314          5.245223  \n",
       "4         183          4.551913  \n",
       "5         211          4.886256  \n",
       "6         210          4.371429  \n",
       "7         570          4.584211  \n",
       "8         410          4.539024  \n",
       "9         267          4.947566  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['mean_word_length'] = train_data['review'].map(lambda rev: np.mean([len(word) for word in rev.split()]))\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0eaa942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>892</td>\n",
       "      <td>161</td>\n",
       "      <td>4.546584</td>\n",
       "      <td>67.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>937</td>\n",
       "      <td>170</td>\n",
       "      <td>4.517647</td>\n",
       "      <td>186.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>468</td>\n",
       "      <td>69</td>\n",
       "      <td>5.797101</td>\n",
       "      <td>66.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1960</td>\n",
       "      <td>314</td>\n",
       "      <td>5.245223</td>\n",
       "      <td>653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1015</td>\n",
       "      <td>183</td>\n",
       "      <td>4.551913</td>\n",
       "      <td>100.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opera (the U.S. title is terror at the opera) ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1241</td>\n",
       "      <td>211</td>\n",
       "      <td>4.886256</td>\n",
       "      <td>123.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heard about this film a long while ago and fin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1127</td>\n",
       "      <td>210</td>\n",
       "      <td>4.371429</td>\n",
       "      <td>124.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3182</td>\n",
       "      <td>570</td>\n",
       "      <td>4.584211</td>\n",
       "      <td>101.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is worth mentioning that is omitted in th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2270</td>\n",
       "      <td>410</td>\n",
       "      <td>4.539024</td>\n",
       "      <td>453.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darling Lili is fantastic! Its by far one my f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1587</td>\n",
       "      <td>267</td>\n",
       "      <td>4.947566</td>\n",
       "      <td>87.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  review_length  \\\n",
       "0  I caught this little gem totally by accident b...  positive            892   \n",
       "1  I can't believe that I let myself into this mo...  negative            937   \n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative            468   \n",
       "3  If there's one thing I've learnt from watching...  negative           1960   \n",
       "4  I remember when this was in theaters, reviews ...  negative           1015   \n",
       "5  Opera (the U.S. title is terror at the opera) ...  positive           1241   \n",
       "6  Heard about this film a long while ago and fin...  positive           1127   \n",
       "7  John Holmes is so famous, he's infamous (as th...  positive           3182   \n",
       "8  What is worth mentioning that is omitted in th...  positive           2270   \n",
       "9  Darling Lili is fantastic! Its by far one my f...  positive           1587   \n",
       "\n",
       "   word_count  mean_word_length  mean_sentence_length  \n",
       "0         161          4.546584             67.692308  \n",
       "1         170          4.517647            186.600000  \n",
       "2          69          5.797101             66.142857  \n",
       "3         314          5.245223            653.000000  \n",
       "4         183          4.551913            100.600000  \n",
       "5         211          4.886256            123.200000  \n",
       "6         210          4.371429            124.333333  \n",
       "7         570          4.584211            101.677419  \n",
       "8         410          4.539024            453.200000  \n",
       "9         267          4.947566             87.333333  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['mean_sentence_length'] = train_data['review'].map(lambda rev: np.mean([len(sent) for sent in nltk.tokenize.sent_tokenize(rev)]))\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea7f310",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sentence_length</th>\n",
       "      <th>Clean_reviews_with_lemm</th>\n",
       "      <th>Clean_reviews_with_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>892</td>\n",
       "      <td>161</td>\n",
       "      <td>4.546584</td>\n",
       "      <td>67.692308</td>\n",
       "      <td>catch little gem totally accident back revival...</td>\n",
       "      <td>caught littl gem total accid back reviv theatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>937</td>\n",
       "      <td>170</td>\n",
       "      <td>4.517647</td>\n",
       "      <td>186.600000</td>\n",
       "      <td>believe let movie accomplish favor friends ask...</td>\n",
       "      <td>believ let movi accomplish favor friend ask ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>468</td>\n",
       "      <td>69</td>\n",
       "      <td>5.797101</td>\n",
       "      <td>66.142857</td>\n",
       "      <td>spoiler alert get nerve people remake use term...</td>\n",
       "      <td>spoiler alert get nerv peopl remak use term lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1960</td>\n",
       "      <td>314</td>\n",
       "      <td>5.245223</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>one thing learn watch george romero creepshow ...</td>\n",
       "      <td>one thing learnt watch georg romero creepshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1015</td>\n",
       "      <td>183</td>\n",
       "      <td>4.551913</td>\n",
       "      <td>100.600000</td>\n",
       "      <td>remember theaters review say horrible well thi...</td>\n",
       "      <td>rememb theater review said horribl well think ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  review_length  \\\n",
       "0  I caught this little gem totally by accident b...  positive            892   \n",
       "1  I can't believe that I let myself into this mo...  negative            937   \n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative            468   \n",
       "3  If there's one thing I've learnt from watching...  negative           1960   \n",
       "4  I remember when this was in theaters, reviews ...  negative           1015   \n",
       "\n",
       "   word_count  mean_word_length  mean_sentence_length  \\\n",
       "0         161          4.546584             67.692308   \n",
       "1         170          4.517647            186.600000   \n",
       "2          69          5.797101             66.142857   \n",
       "3         314          5.245223            653.000000   \n",
       "4         183          4.551913            100.600000   \n",
       "\n",
       "                             Clean_reviews_with_lemm  \\\n",
       "0  catch little gem totally accident back revival...   \n",
       "1  believe let movie accomplish favor friends ask...   \n",
       "2  spoiler alert get nerve people remake use term...   \n",
       "3  one thing learn watch george romero creepshow ...   \n",
       "4  remember theaters review say horrible well thi...   \n",
       "\n",
       "                             Clean_reviews_with_stem  \n",
       "0  caught littl gem total accid back reviv theatr...  \n",
       "1  believ let movi accomplish favor friend ask ea...  \n",
       "2  spoiler alert get nerv peopl remak use term lo...  \n",
       "3  one thing learnt watch georg romero creepshow ...  \n",
       "4  rememb theater review said horribl well think ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "cnt = Counter()\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean_review_with_lemmatizer(review_text):\n",
    "    review_text = str(review_text).lower()\n",
    "    review_text = re.sub('[^a-zA-Z]',' ',review_text)\n",
    "    review_text = word_tokenize(review_text)\n",
    "    review_text = [word for word in review_text if word not in STOPWORDS]\n",
    "    review_text = [lemma.lemmatize(word=w,pos='v') for w in review_text]\n",
    "    review_text = [word for word in review_text if len(word) > 2]\n",
    "    review_text = ' '.join(review_text)\n",
    "    return review_text\n",
    "\n",
    "def clean_review_with_stemmer(review_text):\n",
    "    review_text = str(review_text).lower()\n",
    "    review_text = re.sub('[^a-zA-Z]',' ',review_text)\n",
    "    review_text = word_tokenize(review_text)\n",
    "    review_text = [word for word in review_text if word not in STOPWORDS]\n",
    "    review_text = [stemmer.stem(w) for w in review_text]\n",
    "    review_text = [word for word in review_text if len(word) > 2]\n",
    "    review_text = ' '.join(review_text)\n",
    "    return review_text\n",
    "\n",
    "train_data['Clean_reviews_with_lemm'] = train_data['review'].apply(clean_review_with_lemmatizer)\n",
    "train_data['Clean_reviews_with_stem'] = train_data['review'].apply(clean_review_with_stemmer)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7973c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_lemm, X_test_lemm, y_train, y_test = train_test_split(train_data['Clean_reviews_with_lemm'], train_data['sentiment'], test_size=0.2, random_state=42)\n",
    "X_train_stem, X_test_stem, y_train, y_test = train_test_split(train_data['Clean_reviews_with_stem'], train_data['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a224901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_lemm = CountVectorizer(ngram_range=(1,2))\n",
    "vectorized_lemm_reviews_train = vectorizer_lemm.fit_transform(X_train_lemm);\n",
    "vectorized_lemm_reviews_test = vectorizer_lemm.transform(X_test_lemm);\n",
    "\n",
    "vectorizer_stem = CountVectorizer(ngram_range=(1,2))\n",
    "vectorized_stem_reviews_train = vectorizer_stem.fit_transform(X_train_stem)\n",
    "vectorized_stem_reviews_test = vectorizer_stem.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5760f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_lemm = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_lemm_tfidf = tfidf_vectorizer_lemm.fit_transform(X_train_lemm)\n",
    "X_test_lemm_tfidf = tfidf_vectorizer_lemm.transform(X_test_lemm)\n",
    "\n",
    "tfidf_vectorizer_stem = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_stem_tfidf = tfidf_vectorizer_stem.fit_transform(X_train_stem)\n",
    "X_test_stem_tfidf = tfidf_vectorizer_stem.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6d7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.88125\n",
      "Accuracy with stemming: 0.877625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NB_model_lemm = MultinomialNB()\n",
    "NB_model_lemm.fit(vectorized_lemm_reviews_train, y_train)\n",
    "\n",
    "y_pred_lemm = NB_model_lemm.predict(vectorized_lemm_reviews_test)\n",
    "\n",
    "nb_accuracy_lemm = accuracy_score(y_test, y_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", nb_accuracy_lemm)\n",
    "\n",
    "NB_model_stem = MultinomialNB()\n",
    "NB_model_stem.fit(vectorized_stem_reviews_train, y_train)\n",
    "\n",
    "y_pred_stem = NB_model_stem.predict(vectorized_stem_reviews_test)\n",
    "\n",
    "nb_accuracy_stem = accuracy_score(y_test, y_pred_stem)\n",
    "print(\"Accuracy with stemming:\", nb_accuracy_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a17da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.891\n",
      "Accuracy with stemming: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model_lemm = SVC(C = 1.0,kernel='linear')\n",
    "svm_model_lemm.fit(vectorized_lemm_reviews_train, y_train)\n",
    "\n",
    "svm_pred_lemm = svm_model_lemm.predict(vectorized_lemm_reviews_test)\n",
    "\n",
    "svm_accuracy_lemm = accuracy_score(y_test, svm_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", svm_accuracy_lemm)\n",
    "\n",
    "svm_model_stem = SVC(kernel='linear')\n",
    "svm_model_stem.fit(vectorized_stem_reviews_train, y_train)\n",
    "\n",
    "svm_pred_stem = svm_model_stem.predict(vectorized_stem_reviews_test)\n",
    "\n",
    "svm_accuracy_stem = accuracy_score(y_test, svm_pred_stem)\n",
    "print(\"Accuracy with stemming:\", svm_accuracy_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d5a5340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.895\n",
      "Accuracy with stemming: 0.893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_model_lemm = LogisticRegression(max_iter=500)\n",
    "LR_model_lemm.fit(vectorized_lemm_reviews_train, y_train)\n",
    "\n",
    "LR_pred_lemm = LR_model_lemm.predict(vectorized_lemm_reviews_test)\n",
    "LR_accuracy_lemm = accuracy_score(y_test, LR_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", LR_accuracy_lemm)\n",
    "\n",
    "LR_model_stem = LogisticRegression(max_iter=500)\n",
    "LR_model_stem.fit(vectorized_stem_reviews_train, y_train)\n",
    "\n",
    "LR_pred_stem = LR_model_stem.predict(vectorized_stem_reviews_test)\n",
    "LR_accuracy_stem = accuracy_score(y_test, LR_pred_stem)\n",
    "print(\"Accuracy with stemming:\", LR_accuracy_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e52f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.8845\n",
      "Accuracy with stemming: 0.883625\n"
     ]
    }
   ],
   "source": [
    "NB_model_lemm = MultinomialNB()\n",
    "NB_model_lemm.fit(X_train_lemm_tfidf, y_train)\n",
    "\n",
    "y_pred_lemm = NB_model_lemm.predict(X_test_lemm_tfidf)\n",
    "\n",
    "nb_accuracy_lemm1 = accuracy_score(y_test, y_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", nb_accuracy_lemm1)\n",
    "\n",
    "NB_model_stem = MultinomialNB()\n",
    "NB_model_stem.fit(X_train_stem_tfidf, y_train)\n",
    "\n",
    "y_pred_stem = NB_model_stem.predict(X_test_stem_tfidf)\n",
    "\n",
    "nb_accuracy_stem1 = accuracy_score(y_test, y_pred_stem)\n",
    "print(\"Accuracy with stemming:\", nb_accuracy_stem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e56dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.90425\n",
      "Accuracy with stemming: 0.903875\n"
     ]
    }
   ],
   "source": [
    "svm_model_lemm = SVC(C=1.0, kernel='linear')\n",
    "svm_model_lemm.fit(X_train_lemm_tfidf, y_train)\n",
    "\n",
    "svm_pred_lemm = svm_model_lemm.predict(X_test_lemm_tfidf)\n",
    "\n",
    "svm_accuracy_lemm1 = accuracy_score(y_test, svm_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", svm_accuracy_lemm1)\n",
    "\n",
    "svm_model_stem = SVC(C=1.0,kernel='linear')\n",
    "svm_model_stem.fit(X_train_stem_tfidf, y_train)\n",
    "\n",
    "svm_pred_stem = svm_model_stem.predict(X_test_stem_tfidf)\n",
    "\n",
    "svm_accuracy_stem1 = accuracy_score(y_test, svm_pred_stem)\n",
    "print(\"Accuracy with stemming:\", svm_accuracy_stem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2243f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with lemmatization: 0.887125\n",
      "Accuracy with stemming: 0.886875\n"
     ]
    }
   ],
   "source": [
    "LR_model_lemm = LogisticRegression(max_iter=500)\n",
    "LR_model_lemm.fit(X_train_lemm_tfidf, y_train)\n",
    "\n",
    "LR_pred_lemm = LR_model_lemm.predict(X_test_lemm_tfidf)\n",
    "\n",
    "LR_accuracy_lemm1 = accuracy_score(y_test, LR_pred_lemm)\n",
    "print(\"Accuracy with lemmatization:\", LR_accuracy_lemm1)\n",
    "\n",
    "LR_model_stem = LogisticRegression(max_iter=500)\n",
    "LR_model_stem.fit(X_train_stem_tfidf, y_train)\n",
    "\n",
    "LR_pred_stem = LR_model_stem.predict(X_test_stem_tfidf)\n",
    "\n",
    "LR_accuracy_stem1 = accuracy_score(y_test, LR_pred_stem)\n",
    "print(\"Accuracy with stemming:\", LR_accuracy_stem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5315a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Results with Count vectorizer ######\n",
      "              Naive Bayes   SVM Logistic Regression\n",
      "Lemmatization      88.125  89.1                89.5\n",
      "Stemming          87.7625  89.0                89.3\n",
      "##### Results with TF-IDF vectorizer ######\n",
      "              Naive Bayes      SVM Logistic Regression\n",
      "Lemmatization       88.45   90.425             88.7125\n",
      "Stemming          88.3625  90.3875             88.6875\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Results with Count vectorizer ######\")\n",
    "\n",
    "df = pd.DataFrame(index=['Lemmatization','Stemming'], columns=['Naive Bayes','SVM','Logistic Regression'])\n",
    "df.loc['Lemmatization', 'Naive Bayes'] = nb_accuracy_lemm * 100\n",
    "df.loc['Lemmatization', 'SVM'] = svm_accuracy_lemm * 100\n",
    "df.loc['Lemmatization', 'Logistic Regression'] = LR_accuracy_lemm * 100\n",
    "\n",
    "df.loc['Stemming', 'Naive Bayes'] = nb_accuracy_stem * 100\n",
    "df.loc['Stemming', 'SVM'] = svm_accuracy_stem * 100\n",
    "df.loc['Stemming', 'Logistic Regression'] = LR_accuracy_stem * 100\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(\"##### Results with TF-IDF vectorizer ######\")\n",
    "\n",
    "df1 = pd.DataFrame(index=['Lemmatization','Stemming'], columns=['Naive Bayes','SVM','Logistic Regression'])\n",
    "df1.loc['Lemmatization', 'Naive Bayes'] = nb_accuracy_lemm1 * 100\n",
    "df1.loc['Lemmatization', 'SVM'] = svm_accuracy_lemm1 * 100\n",
    "df1.loc['Lemmatization', 'Logistic Regression'] = LR_accuracy_lemm1 * 100\n",
    "\n",
    "df1.loc['Stemming', 'Naive Bayes'] = nb_accuracy_stem1 * 100\n",
    "df1.loc['Stemming', 'SVM'] = svm_accuracy_stem1 * 100\n",
    "df1.loc['Stemming', 'Logistic Regression'] = LR_accuracy_stem1 * 100\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a46b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'],'gamma': [0.1, 0.01, 0.001, 0.0001]}\n",
    "svm_model_lemm = SVC()\n",
    "grid_search = GridSearchCV(svm_model_lemm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_lemm_tfidf, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "svm_pred_lemm_best = grid_search.best_estimator_.predict(X_test_lemm_tfidf)\n",
    "svm_accuracy_lemm_best = accuracy_score(y_test, svm_pred_lemm_best)\n",
    "print(\"Best accuracy with lemmatization:\", svm_accuracy_lemm_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
